{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and images augmentation\n",
    "\n",
    "### Structure of img annotation:\n",
    "```python\n",
    "img = {\n",
    "    'filename': string\n",
    "    'width': int,\n",
    "    'height': int,\n",
    "    'object': [\n",
    "        {\n",
    "            'name': string,  # label name\n",
    "            'xmin': int,\n",
    "            'ymin': int,\n",
    "            'xmax': int,\n",
    "            'ymax': int\n",
    "        }, ...\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.insert(0, '/home/oem/PycharmProjects/tensorflow_yolo/basic-yolo-keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcrowdw_settings = {\n",
    "    'datasets_path': '/media/oem/022cfb2b-3c52-4dfe-a5fb-c5fe826db5e3/Downloads/lcrowdw',\n",
    "    'scene_type': [\n",
    "        # 'shibuya_var/bright', 'shibuya_var/dim',\n",
    "          'shop_var/bright', 'shop_var/dim',\n",
    "        # 'subway_var/bright', 'subway_var/dim'\n",
    "    ],\n",
    "    'people_dense_type': [\n",
    "        'p_hd_hpc_hp',\n",
    "        # 'p_ld_lpc_hp',\n",
    "        # 'p_md_mpc_hp'\n",
    "    ],\n",
    "    'images_subdir': 'png',\n",
    "    'bb_subdir': 'bb'\n",
    "}\n",
    "\n",
    "class Rectangle:\n",
    "    def __init__(self, x_min, x_max, y_min, y_max):\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "        self.y_min = y_min\n",
    "        self.y_max = y_max\n",
    "        \n",
    "        self.x_lenght = np.abs(x_min - x_max)\n",
    "        self.y_lenght = np.abs(y_min - y_max)\n",
    "        \n",
    "        self.area = self.x_lenght * self.y_lenght\n",
    "        \n",
    "    def __lt__(self, rectangle):\n",
    "        return self.area < rectangle.area\n",
    "    \n",
    "    def __eq__(self, rectangle):\n",
    "        return self.x_min == rectangle.x_min \\\n",
    "            and self.x_max == rectangle.x_max \\\n",
    "            and self.y_min == rectangle.y_min \\\n",
    "            and self.y_max == rectangle.y_max\n",
    "        \n",
    "    def has_intersection(self, rectangle):\n",
    "        hoverlaps = not((self.x_min > rectangle.x_max) or (self.x_max < rectangle.x_min))\n",
    "        voverlaps = not((self.y_max < rectangle.y_min) or (self.y_min > rectangle.y_max))\n",
    "        return hoverlaps and voverlaps\n",
    "        \n",
    "    def intersection_percent(self, rectangle):\n",
    "        if not self.has_intersection(rectangle):\n",
    "            return 0.0\n",
    "        \n",
    "        intersection_width = np.abs(min(self.x_max, rectangle.x_max) - max(self.x_min, rectangle.x_min))\n",
    "        intersection_height = np.abs(min(self.y_max, rectangle.y_max) - max(self.y_min, rectangle.y_min))\n",
    "        intersection_area = intersection_width * intersection_height\n",
    "        return (intersection_area / self.area) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_annotation_lcrowdw(bb_dir, images_dir):\n",
    "    imgs = []\n",
    "\n",
    "    def get_sorted_filenamelist(path, ext):\n",
    "        return sorted(\n",
    "            map(lambda filename: os.path.join(path, filename),\n",
    "                filter(lambda filename: filename.endswith(ext),\n",
    "                       os.listdir(path))))\n",
    "\n",
    "    for image_path, ann_path in zip(get_sorted_filenamelist(images_dir, 'png'),\n",
    "                                    get_sorted_filenamelist(bb_dir, 'csv')):\n",
    "        img = {}\n",
    "        img['filename'] = image_path\n",
    "        img['width'], img['height'] = Image.open(image_path).size\n",
    "        \n",
    "        with open(ann_path) as csv_annot:\n",
    "            reader = csv.reader(csv_annot, delimiter=',')\n",
    "            annotations = [\n",
    "                Rectangle(x_min=round(float(row[1])),\n",
    "                          x_max=round(float(row[3])),\n",
    "                          y_min=round(float(row[2])),\n",
    "                          y_max=round(float(row[4])))\n",
    "                for row in reader\n",
    "            ]\n",
    "            annotations = list(filter(lambda ann: not np.any([ann.intersection_percent(ann_) >= 60.0 \n",
    "                                                          for ann_ in filter(lambda x: x != ann, annotations)]), \n",
    "                                      annotations))\n",
    "            img['object'] = [\n",
    "                {\n",
    "                    'name': 'person',\n",
    "                    'xmin': ann.x_min,\n",
    "                    'ymin': ann.y_min,\n",
    "                    'xmax': ann.x_max,\n",
    "                    'ymax': ann.y_max\n",
    "                }\n",
    "                for ann in sorted(annotations)[-20:]\n",
    "            ]\n",
    "        imgs.append(img)\n",
    "\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def _load_all_lcrowdw_annotations(lcrowdw_settings):\n",
    "    all_imgs = []\n",
    "\n",
    "    for scene_type in lcrowdw_settings['scene_type']:\n",
    "        for people_dense_type in lcrowdw_settings['people_dense_type']:\n",
    "            imgs = _parse_annotation_lcrowdw(\n",
    "                os.path.join(lcrowdw_settings['datasets_path'], scene_type, people_dense_type,\n",
    "                             lcrowdw_settings['bb_subdir']),\n",
    "                os.path.join(lcrowdw_settings['datasets_path'],\n",
    "                             scene_type, people_dense_type,\n",
    "                             lcrowdw_settings['images_subdir'])\n",
    "            )\n",
    "            all_imgs += imgs\n",
    "\n",
    "    return all_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = _load_all_lcrowdw_annotations(lcrowdw_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9826), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "\n",
    "\n",
    "def prettify(elem):\n",
    "    rough_string = ET.tostring(elem, 'utf-8')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    return reparsed.toprettyxml(indent='\\t')\n",
    "\n",
    "\n",
    "for img in tqdm_notebook(data):\n",
    "    main = ET.Element('annotation', attrib={'verified': 'no'})\n",
    "    ET.SubElement(main, 'folder').text = 'png'\n",
    "    ET.SubElement(main, 'filename').text = os.path.split(img['filename'])[1]\n",
    "    ET.SubElement(main, 'path').text = img['filename']\n",
    "    ET.SubElement(main, 'segmented').text = '0'\n",
    "\n",
    "    source = ET.SubElement(main, 'segmented')\n",
    "    ET.SubElement(source, 'database').text = 'Unknown'\n",
    "\n",
    "    size = ET.SubElement(main, 'size')\n",
    "    ET.SubElement(size, 'width').text = str(img['width'])\n",
    "    ET.SubElement(size, 'height').text = str(img['height'])\n",
    "    ET.SubElement(size, 'depth').text = '3'\n",
    "\n",
    "    for img_obj in img['object']:\n",
    "        obj = ET.SubElement(main, 'object')\n",
    "        ET.SubElement(obj, 'name').text = 'person'\n",
    "        ET.SubElement(obj, 'pose').text = 'Unspecified'\n",
    "        ET.SubElement(obj, 'truncated').text = '0'\n",
    "        ET.SubElement(obj, 'difficult').text = '0'\n",
    "\n",
    "        bbox = ET.SubElement(obj, 'bndbox')\n",
    "        ET.SubElement(bbox, 'xmin').text = str(img_obj['xmin'])\n",
    "        ET.SubElement(bbox, 'ymin').text = str(img_obj['ymin'])\n",
    "        ET.SubElement(bbox, 'xmax').text = str(img_obj['xmax'])\n",
    "        ET.SubElement(bbox, 'ymax').text = str(img_obj['ymax'])\n",
    "\n",
    "    path, filename = os.path.split(img['filename'])\n",
    "    with open(os.path.join(path, filename[:-4] + '.xml'), 'w') as f:\n",
    "        f.write(prettify(main))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6653), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ann_path = '/media/oem/022cfb2b-3c52-4dfe-a5fb-c5fe826db5e3/Downloads/lcrowdw/shop_var/bright/p_hd_hpc_hp/png/'\n",
    "\n",
    "imgs = []\n",
    "for item in tqdm_notebook(os.listdir(ann_path)):\n",
    "    if not item.endswith('xml'):\n",
    "        continue\n",
    "    tree = ET.parse(os.path.join(ann_path, item))\n",
    "    \n",
    "    if 'verified' in tree.getroot().attrib and tree.getroot().attrib['verified'] != 'yes':\n",
    "        continue\n",
    "        \n",
    "    img = {}\n",
    "    img['filename'] = tree.find('path').text\n",
    "    img['width'], img['height'] = int(tree.find('size').find('width').text), int(tree.find('size').find('height').text)\n",
    "\n",
    "    img['object'] = [\n",
    "                {\n",
    "                    'name': 'person',\n",
    "                    'xmin': int(obj.find('bndbox').find('xmin').text),\n",
    "                    'ymin': int(obj.find('bndbox').find('ymin').text),\n",
    "                    'xmax': int(obj.find('bndbox').find('xmax').text),\n",
    "                    'ymax': int(obj.find('bndbox').find('ymax').text)\n",
    "                }\n",
    "                for obj in tree.findall('object')\n",
    "            ]\n",
    "    imgs.append(img)\n",
    "    \n",
    "with open(os.path.join(ann_path, 'annotations.pickle'), 'wb') as f:\n",
    "    pickle.dump(imgs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_path = '/media/oem/022cfb2b-3c52-4dfe-a5fb-c5fe826db5e3/Downloads/lcrowdw/shop_var/bright/p_hd_hpc_hp/png/'\n",
    "with open(os.path.join(ann_path, 'annotations.pickle'), 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_config = {\n",
    "    'IMAGE_H'         : 500, \n",
    "    'IMAGE_W'         : 500,\n",
    "    'GRID_H'          : 20,  \n",
    "    'GRID_W'          : 20,\n",
    "    'BOX'             : 5,\n",
    "    'LABELS'          : ['person'],\n",
    "    'CLASS'           : 1,\n",
    "    'ANCHORS'         : [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828],\n",
    "    'BATCH_SIZE'      : 16,\n",
    "    'TRUE_BOX_BUFFER' : 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = BatchGenerator(data, generator_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:29: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05c6df5128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "def imshow_grid(data, height=None, width=None, normalize=False, padsize=1, padval=0):\n",
    "    '''\n",
    "    Take an array of shape (N, H, W) or (N, H, W, C)\n",
    "    and visualize each (H, W) image in a grid style (height x width).\n",
    "    '''\n",
    "    if normalize:\n",
    "        data -= data.min()\n",
    "        data /= data.max()\n",
    "\n",
    "    N = data.shape[0]\n",
    "    if height is None:\n",
    "        if width is None:\n",
    "            height = int(np.ceil(np.sqrt(N)))\n",
    "        else:\n",
    "            height = int(np.ceil( N / float(width) ))\n",
    "\n",
    "    if width is None:\n",
    "        width = int(np.ceil( N / float(height) ))\n",
    "\n",
    "    assert height * width >= N\n",
    "\n",
    "    # append padding\n",
    "    padding = ((0, (width*height) - data.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant', constant_values=(padval, padval))\n",
    "\n",
    "    # tile the filters into an image\n",
    "    data = data.reshape((height, width) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((height * data.shape[1], width * data.shape[3]) + data.shape[4:])\n",
    "\n",
    "    plt.imshow(data)\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "imshow_grid(batches[6][0][0], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import filecmp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "OPEN_IMAGES_PATH = '/media/oem/022cfb2b-3c52-4dfe-a5fb-c5fe826db5e3/openimages/'\n",
    "\n",
    "\n",
    "def get_existing_pictures():\n",
    "    return set([f.split('.')[0] for f in os.listdir(os.path.join(OPEN_IMAGES_PATH, 'images_dataset')) \n",
    "                if f.endswith('.jpg')])\n",
    "\n",
    "\n",
    "def parse_openimages():\n",
    "    annotations_box = pd.read_pickle(os.path.join(OPEN_IMAGES_PATH, 'annotations_box.pickle'))\n",
    "    dict_ = pd.read_pickle(os.path.join(OPEN_IMAGES_PATH, 'dict.pickle'))\n",
    "    \n",
    "    existing_pictures = set([f.split('.')[0] \n",
    "                             for f in os.listdir(os.path.join(OPEN_IMAGES_PATH, 'images_dataset')) \n",
    "                             if f.endswith('.jpg') and f.split('.')[0] in annotations_box.index])\n",
    "    \n",
    "    person_label_names = {\n",
    "        dict_[dict_['label_display_name'] == name].index[0]: name\n",
    "        for name in ['Person', 'Man', 'Woman', 'Boy', 'Girl']\n",
    "    }\n",
    "    \n",
    "    annotations_box = annotations_box[annotations_box['label_name'].isin(person_label_names.keys())]\n",
    "    annotations_box = annotations_box[annotations_box.index.isin(existing_pictures)]\n",
    "    annotations_box = annotations_box.drop(['source', 'confidence', 'is_occluded', \n",
    "                                            'is_truncated', 'is_group_of', 'is_depiction', 'is_inside'], \n",
    "                                           axis=1)\n",
    "    \n",
    "    images = []\n",
    "    for f in tqdm_notebook(existing_pictures):\n",
    "        filtered_annotations_box = annotations_box[annotations_box.index == f]\n",
    "                                                       \n",
    "        if len(filtered_annotations_box) == 0:\n",
    "            continue\n",
    "        \n",
    "        img = {}\n",
    "        image_filename = os.path.join(OPEN_IMAGES_PATH, 'images_dataset', f + '.jpg')\n",
    "        img['filename'] = f + '.jpg'\n",
    "        img['width'], img['height'] = Image.open(image_filename).size\n",
    "\n",
    "        img['object'] = [\n",
    "                {\n",
    "                    'name': 'person',\n",
    "                    'xmin': int(annot_row['x_min'] * img['width']),\n",
    "                    'xmax': int(annot_row['x_max'] * img['width']),\n",
    "                    'ymin': int(annot_row['y_min'] * img['height']),\n",
    "                    'ymax': int(annot_row['y_max'] * img['height'])\n",
    "                }\n",
    "                for _, annot_row in filtered_annotations_box.iterrows()\n",
    "            ]\n",
    "        \n",
    "        images.append(img)\n",
    "        \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = parse_openimages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in data:\n",
    "    img['filename'] = os.path.join(OPEN_IMAGES_PATH, 'images_dataset', img['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_existing_files():\n",
    "    return [os.path.join(OPEN_IMAGES_PATH, 'images_dataset', f)\n",
    "            for f in os.listdir(os.path.join(OPEN_IMAGES_PATH, 'images_dataset')) \n",
    "            if f.endswith('.jpg')]\n",
    "\n",
    "error_images = [os.path.join(OPEN_IMAGES_PATH, 'images_dataset', 'flickr_notfound_small.jpg'), \n",
    "                os.path.join(OPEN_IMAGES_PATH, 'images_dataset', 'flickr_notfound_big.jpg')]\n",
    "existing_pictures = get_existing_files()\n",
    "bad_images = set()\n",
    "for image_filename in tqdm_notebook(existing_pictures[:1000]):\n",
    "    try:\n",
    "        image_size = os.stat(image_filename).st_size\n",
    "        assert image_size > 1024  # It must be more than 1Kb\n",
    "        assert not np.any([filecmp.cmp(i, image_filename) for i in error_images])\n",
    "\n",
    "        image = Image.open(image_filename)\n",
    "        image.verify()\n",
    "\n",
    "        assert image.size[0] < 10000 and image.size[1] < 10000  # Too big image for Flickr (likely it is invalid image)\n",
    "    except:\n",
    "        bad_images.add(image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(OPEN_IMAGES_PATH, 'images_annotations.pickle'), 'rb') as f:\n",
    "    images = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_filtered = list(filter(lambda x: len(x['object']) > 1, images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_dataset_path = '/media/oem/022cfb2b-3c52-4dfe-a5fb-c5fe826db5e3/Downloads/queue_dataset/'\n",
    "\n",
    "def load_queue_dataset():\n",
    "    images = []\n",
    "    \n",
    "    for folder in os.listdir(queue_dataset_path):\n",
    "        frames_path = os.path.join(queue_dataset_path, folder, 'data/obj/')\n",
    "        \n",
    "        for image_filename in os.listdir(frames_path):\n",
    "            if not image_filename.endswith('jpg'):\n",
    "                continue\n",
    "            image = {}\n",
    "            image['filename'] = os.path.join(frames_path, image_filename)\n",
    "            \n",
    "            \n",
    "            with open(image['filename'][:-4] + '.txt') as f:\n",
    "                reader = csv.reader(f, delimiter=' ')\n",
    "                objects = [list(map(float, row[1:])) for row in reader]\n",
    "                \n",
    "            image['object'] = [{\n",
    "                'name': 'person',\n",
    "                'xmin': int(o[0] * image['width']) - (int(o[2] * image['width']) // 2),\n",
    "                'ymin': int(o[1] * image['height']) - (int(o[3] * image['height']) // 2),\n",
    "                'xmax': int(o[0] * image['width']) + (int(o[2] * image['width']) // 2),\n",
    "                'ymax': int(o[1] * image['height']) + (int(o[3] * image['height']) // 2)\n",
    "            } for o in objects]\n",
    "            \n",
    "            images.append(image)\n",
    "            \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_queue_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "prw_dataset_path = '/media/oem/022cfb2b-3c52-4dfe-a5fb-c5fe826db5e3/Downloads/PRW-v16.04.20/'\n",
    "\n",
    "\n",
    "def load_prw_dataset():\n",
    "    images = []\n",
    "    \n",
    "    for image_filename in tqdm_notebook(os.listdir(os.path.join(prw_dataset_path, 'frames'))):\n",
    "        if not image_filename.endswith('jpg'):\n",
    "            continue\n",
    "            \n",
    "        image = {}\n",
    "        image['filename'] = os.path.join(prw_dataset_path, 'frames', image_filename)\n",
    "        image['width'], image['height'] = Image.open(image['filename']).size\n",
    "        \n",
    "        with open(os.path.join(prw_dataset_path, 'annotations', image_filename + '.mat'), 'rb') as f:\n",
    "            objects = loadmat(f)\n",
    "            if 'box_new' not in objects:\n",
    "                continue\n",
    "                \n",
    "        objects = objects['box_new'][:,1:].astype(np.int)\n",
    "        image['object'] = [{\n",
    "                    'name': 'person',\n",
    "                    'xmin': o[0],\n",
    "                    'ymin': o[1],\n",
    "                    'xmax': o[0] + o[2],\n",
    "                    'ymax': o[1] + o[3] \n",
    "                } for o in objects]\n",
    "        images.append(image)\n",
    "        \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_prw_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_path = '/media/oem/022cfb2b-3c52-4dfe-a5fb-c5fe826db5e3/samples/peoples/queue_dataset/'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
