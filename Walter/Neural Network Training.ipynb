{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Dense, Flatten, Add, InputLayer\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageHeight = 224\n",
    "ImageWidth = 224\n",
    "ArchSelect = 'VGG16'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Structure of Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 Structure : \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 1285      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 23,041,989\n",
      "Trainable params: 23,040,965\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if ArchSelect == 'VGG16':\n",
    "    print('VGG16 Structure : ')\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=64 ,kernel_size=(3,3), padding='same', input_shape=(ImageHeight, ImageWidth, 1), activation='relu'))\n",
    "    model.add(Conv2D(filters=64 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=128 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=128 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=256 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=256 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=256 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=512 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=512 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=512 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=512 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=512 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=512 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=512 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=512 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=512 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=5))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "\n",
    "elif ArchSelect == 'LeNet':\n",
    "    print('LeNet Structure : ')\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=6, kernel_size=(5,5), input_shape=(ImageHeight, ImageWidth,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=16, kernel_size=(5,5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=120))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=84))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=5))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "\n",
    "else:\n",
    "    print('Regular CNN Structure : ')\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=64 ,kernel_size=(3,3), padding='same', input_shape=(ImageHeight, ImageWidth,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=128 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=256 ,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=5))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set shape : (200, 224, 224, 1)\n",
      "train label shape : (200, 5)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import gc\n",
    "SampleNumber = 40\n",
    "train_label = np.zeros(shape=(SampleNumber*5,), dtype = np.float16)\n",
    "\n",
    "\n",
    "train_down = np.zeros(shape=(SampleNumber,ImageHeight, ImageWidth, 1), dtype = np.float16)\n",
    "for Sample in range(SampleNumber):\n",
    "    img = cv.imread('down/down%d'%Sample+'.jpg', cv.COLOR_BGR2GRAY)\n",
    "    img = cv.resize(img,(ImageHeight,ImageWidth))\n",
    "    train_down[Sample] = img.reshape(-1, ImageHeight, ImageWidth, 1)\n",
    "    train_label[Sample] = 1\n",
    "\n",
    "train_up = np.zeros(shape=(SampleNumber,ImageHeight, ImageWidth, 1), dtype = np.float16)\n",
    "for Sample in range(SampleNumber):\n",
    "    img = cv.imread('up/up%d'%Sample+'.jpg', cv.COLOR_BGR2GRAY)\n",
    "    img = cv.resize(img,(ImageHeight,ImageWidth))\n",
    "    train_up[Sample] = img.reshape(-1, ImageHeight, ImageWidth, 1)\n",
    "    train_label[Sample+SampleNumber] = 2\n",
    "\n",
    "train_right = np.zeros(shape=(SampleNumber,ImageHeight, ImageWidth, 1), dtype = np.float16)\n",
    "for Sample in range(SampleNumber):\n",
    "    img = cv.imread('right/right%d'%Sample+'.jpg', cv.COLOR_BGR2GRAY)\n",
    "    img = cv.resize(img,(ImageHeight,ImageWidth))\n",
    "    train_right[Sample] = img.reshape(-1, ImageHeight, ImageWidth, 1)\n",
    "    train_label[Sample+SampleNumber*2] = 3\n",
    "    \n",
    "train_left = np.zeros(shape=(SampleNumber,ImageHeight, ImageWidth, 1), dtype = np.float16)\n",
    "for Sample in range(SampleNumber):\n",
    "    img = cv.imread('left/left%d'%Sample+'.jpg', cv.COLOR_BGR2GRAY)\n",
    "    img = cv.resize(img,(ImageHeight,ImageWidth))\n",
    "    train_left[Sample] = img.reshape(-1, ImageHeight, ImageWidth, 1)\n",
    "    train_label[Sample+SampleNumber*3] = 4\n",
    "\n",
    "train_other = np.zeros(shape=(SampleNumber,ImageHeight, ImageWidth, 1), dtype = np.float16)\n",
    "for Sample in range(SampleNumber):\n",
    "    img = cv.imread('other/other%d'%Sample+'.jpg', cv.COLOR_BGR2GRAY)\n",
    "    img = cv.resize(img,(ImageHeight,ImageWidth))\n",
    "    train_other[Sample] = img.reshape(-1, ImageHeight, ImageWidth, 1)\n",
    "    train_label[Sample+SampleNumber*4] = 0\n",
    "    \n",
    "    \n",
    "train_set = np.append(train_down, train_up ,axis=0)\n",
    "train_set = np.append(train_set, train_right ,axis=0)\n",
    "train_set = np.append(train_set, train_left ,axis=0)\n",
    "train_set = np.append(train_set, train_other ,axis=0)\n",
    "del train_down, train_up, train_left, train_right, train_other\n",
    "gc.collect()\n",
    "\n",
    "train_labels = np_utils.to_categorical(train_label)\n",
    "\n",
    "print(\"train set shape :\",train_set.shape)\n",
    "print(\"train label shape :\",train_labels.shape)\n",
    "# down : 1, up : 2, right : 3, left : 4, other :0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make sure train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e237a69898>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(2,3,1)\n",
    "img = Image.fromarray(train_set[0].reshape(ImageHeight, ImageWidth).astype('uint8'))\n",
    "plt.imshow(img)\n",
    "plt.subplot(2,3,2)\n",
    "img = Image.fromarray(train_set[20].reshape(ImageHeight, ImageWidth).astype('uint8'))\n",
    "plt.imshow(img)\n",
    "plt.subplot(2,3,3)\n",
    "img = Image.fromarray(train_set[40].reshape(ImageHeight, ImageWidth).astype('uint8'))\n",
    "plt.imshow(img)\n",
    "plt.subplot(2,3,4)\n",
    "img = Image.fromarray(train_set[60].reshape(ImageHeight, ImageWidth).astype('uint8'))\n",
    "plt.imshow(img)\n",
    "plt.subplot(2,3,5)\n",
    "img = Image.fromarray(train_set[80].reshape(ImageHeight, ImageWidth).astype('uint8'))\n",
    "plt.imshow(img)\n",
    "plt.subplot(2,3,6)\n",
    "img = Image.fromarray(train_set[99].reshape(ImageHeight, ImageWidth).astype('uint8'))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190 samples, validate on 10 samples\n",
      "Epoch 1/30\n",
      "190/190 [==============================] - 18s 94ms/step - loss: 0.9770 - acc: 0.6368 - val_loss: 4.2284 - val_acc: 0.1000\n",
      "Epoch 2/30\n",
      "190/190 [==============================] - 10s 51ms/step - loss: 0.6418 - acc: 0.7737 - val_loss: 1.5544 - val_acc: 0.5000\n",
      "Epoch 3/30\n",
      "190/190 [==============================] - 10s 52ms/step - loss: 0.5013 - acc: 0.8474 - val_loss: 1.7563 - val_acc: 0.5000\n",
      "Epoch 4/30\n",
      "190/190 [==============================] - 10s 51ms/step - loss: 0.5074 - acc: 0.8368 - val_loss: 1.8011 - val_acc: 0.5000\n",
      "Epoch 5/30\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.4883 - acc: 0.8579 - val_loss: 0.3662 - val_acc: 0.7000\n",
      "Epoch 6/30\n",
      "190/190 [==============================] - 10s 50ms/step - loss: 0.4449 - acc: 0.8737 - val_loss: 0.5060 - val_acc: 0.7000\n",
      "Epoch 7/30\n",
      "190/190 [==============================] - 10s 50ms/step - loss: 0.3259 - acc: 0.8947 - val_loss: 2.2608 - val_acc: 0.4000\n",
      "Epoch 8/30\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3475 - acc: 0.9000 - val_loss: 0.1492 - val_acc: 1.0000\n",
      "Epoch 9/30\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3140 - acc: 0.9105 - val_loss: 0.9993 - val_acc: 0.7000\n",
      "Epoch 10/30\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.3360 - acc: 0.9105 - val_loss: 0.3709 - val_acc: 0.8000\n",
      "Epoch 11/30\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.2935 - acc: 0.9000 - val_loss: 1.2437 - val_acc: 0.7000\n",
      "Epoch 12/30\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.2566 - acc: 0.9211 - val_loss: 1.5006 - val_acc: 0.5000\n",
      "Epoch 13/30\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.1994 - acc: 0.9368 - val_loss: 0.3388 - val_acc: 0.9000\n",
      "Epoch 14/30\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.1872 - acc: 0.9316 - val_loss: 0.2943 - val_acc: 0.8000\n",
      "Epoch 15/30\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.1852 - acc: 0.9474 - val_loss: 0.2185 - val_acc: 0.9000\n",
      "Epoch 16/30\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.1193 - acc: 0.9737 - val_loss: 0.7753 - val_acc: 0.8000\n",
      "Epoch 17/30\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.1111 - acc: 0.9789 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.1466 - acc: 0.9474 - val_loss: 0.5356 - val_acc: 0.8000\n",
      "Epoch 19/30\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.1283 - acc: 0.9526 - val_loss: 0.0476 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.1554 - acc: 0.9579 - val_loss: 0.8892 - val_acc: 0.8000\n",
      "Epoch 21/30\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.1906 - acc: 0.9474 - val_loss: 0.1812 - val_acc: 0.8000\n",
      "Epoch 22/30\n",
      "190/190 [==============================] - 9s 47ms/step - loss: 0.0820 - acc: 0.9895 - val_loss: 0.3636 - val_acc: 0.9000\n",
      "Epoch 23/30\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.1284 - acc: 0.9632 - val_loss: 0.5297 - val_acc: 0.7000\n",
      "Epoch 24/30\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.0886 - acc: 0.9737 - val_loss: 1.2927 - val_acc: 0.7000\n",
      "Epoch 25/30\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.0759 - acc: 0.9737 - val_loss: 1.0046 - val_acc: 0.7000\n",
      "Epoch 26/30\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.0704 - acc: 0.9895 - val_loss: 0.0527 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.0386 - acc: 1.0000 - val_loss: 0.3052 - val_acc: 0.8000\n",
      "Epoch 28/30\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.0471 - acc: 0.9895 - val_loss: 0.1242 - val_acc: 0.9000\n",
      "Epoch 29/30\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.0682 - acc: 0.9895 - val_loss: 0.3270 - val_acc: 0.9000\n",
      "Epoch 30/30\n",
      "190/190 [==============================] - 9s 48ms/step - loss: 0.1136 - acc: 0.9526 - val_loss: 0.2201 - val_acc: 0.9000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "epochs = 30\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),metrics=['accuracy'])\n",
    "history = model.fit(x=train_set, y=train_labels, batch_size=batch_size, epochs=epochs, verbose=1,shuffle=True, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('model_DHG_VGG16_224_S40.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
